{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing Assignment\n",
    "\n",
    "## This notebook contains the documentation and solution to the large data processing class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set Description : The dataset was created for the comparison and evaluation of hybrid indoor positioning methods. The dataset presented contains data from W-LAN and Bluetooth interfaces, and Magnetometer.\n",
    "\n",
    "The measurements were recorded with a android application running on an android phone. \n",
    "The x, y, z coordinates were mapped onto the building by placing notes on the wall.\n",
    "During a measurement, the room name, and coordinates were input by the measuring user.\n",
    "The application sent a message to a server-side application which stored them in a SQL database.\n",
    "\n",
    "\n",
    "### The dataset is made up of the following features:\n",
    "* First 10 features are dense:\n",
    " - Measurement ID\n",
    " - Timestamp\n",
    " - Measurement Coordinates (input by hand, can have errors)\n",
    " - Symbolic Position (UUID+ Name of the room)\n",
    " \n",
    " \n",
    "* Rest of the features Highly Sparse (11-65) are sparse. At every measurement the following values are recorded:\n",
    " - Features from 11 to 42 represent the buildings' WiFi Access Point Received Signal Strenght (RSSI). \n",
    "      - At every measurement, every reachable WiFI RSSI is measured.\n",
    "      - If an acces point is unreachable, it is left as null.\n",
    " - Selected bluetooth devices are also recorded from feature 42-65. \n",
    "     - The recording strategy is the same as the WiFi RSSI.\n",
    "    \n",
    "\n",
    "The dataset can be inspected and downloaded from the following repository:\n",
    "https://archive.ics.uci.edu/ml/datasets/Miskolc+IIS+Hybrid+IPS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Used Models, Frameworks:\n",
    "\n",
    "\n",
    "* Numpy for array data structure, and  miscellaneous mathematical functions.\n",
    "<img src=\"https://numpy.org/images/logos/numpy.svg\" width=\"100\" height=\"100\" /> \n",
    "\n",
    "* Pandas for the DataFrame and Series data structure, and statistical functions.\n",
    "<img src=\"https://numfocus.org/wp-content/uploads/2016/07/pandas-logo-300.png\" width=\"100\" height=\"100\" /> \n",
    "\n",
    "* Scikit-Learn for easy-to-use machine learning models and functions.\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/0/05/Scikit_learn_logo_small.svg\" width=\"100\" height=\"100\" /> \n",
    "* DEAP for implementing a genetic algorithm model. \n",
    "<img src=\"https://deap.readthedocs.io/en/master/_images/deap_long.png\" width=\"100\" height=\"100\" /> \n",
    "* MatPlotLib for plotting.\n",
    "<img src=\"https://matplotlib.org/_static/logo2_compressed.svg\" width=\"100\" height=\"100\" /> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Description:\n",
    "\n",
    "* There are no readily available Indoor Positioning Systems.\n",
    "* Many approaches, one of the most widely used method uses WiFi RSSI Fingerprinting.\n",
    "* Fingerprinting creates a radio signal map of the building.\n",
    "  - Data mining techniques can be used to create a data set. \n",
    "  - Data set can be used for machine learning and data analysis.\n",
    "* Try to learn inferences between 3d positions and WiFi signal strength with a neural network model.\n",
    "  - Create Neural Network model using Hyperparameter training.\n",
    "* Implement a neural network inversion method in order to predict positions based on measured signal strenghts.\n",
    "    - Positions, and RSSI values are not bijective, therefore there is no clear inverse of the original function.\n",
    "    - Intersect the inverted position surfaces to increase accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution Description :\n",
    "\n",
    "\n",
    "* <a href='#section1'> Step One : Imports, and utility functions </a>\n",
    "* <a href='#section2'> Step Two :  Dataset separation, scaling and simple filtering </a>\n",
    "* <a href='#section3'>Step Three: Hyperparameter Training and Artificial Neural Network Model Building.</a>\n",
    "* <a href='#section4'> Step Four: Genetic Algorithm.  </a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'>   </a>\n",
    "# Step One : Imports, and utility functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block imports all the necessary libraries for the task.\n",
    "the following lines increase the amound of displayed rows and columns in the columns.\n",
    "\n",
    "    pd.set_option('display.max_rows', 500)\n",
    "    pd.set_option('display.max_columns', 500)\n",
    "    pd.set_option('display.width', 1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "import random\n",
    "from deap import base\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measId</th>\n",
       "      <th>measTimestamp</th>\n",
       "      <th>Position X</th>\n",
       "      <th>Position Y</th>\n",
       "      <th>Position Z</th>\n",
       "      <th>zoneId</th>\n",
       "      <th>Zonename</th>\n",
       "      <th>meas X</th>\n",
       "      <th>meas Y</th>\n",
       "      <th>meas Z</th>\n",
       "      <th>gpsLatitude</th>\n",
       "      <th>gpsLongitude</th>\n",
       "      <th>gpsAltitude</th>\n",
       "      <th>N</th>\n",
       "      <th>109.0</th>\n",
       "      <th>AIT-L15</th>\n",
       "      <th>aut-sams-1</th>\n",
       "      <th>bolyai_E4_floor3</th>\n",
       "      <th>Bosch_Telemetry</th>\n",
       "      <th>dd</th>\n",
       "      <th>doa2</th>\n",
       "      <th>doa200</th>\n",
       "      <th>doa203</th>\n",
       "      <th>doa207</th>\n",
       "      <th>doa208</th>\n",
       "      <th>doa6</th>\n",
       "      <th>EET_3</th>\n",
       "      <th>FRM</th>\n",
       "      <th>GEIAKFSZ</th>\n",
       "      <th>IITAP1</th>\n",
       "      <th>IITAP1-GUEST</th>\n",
       "      <th>IITAP2</th>\n",
       "      <th>IITAP2-GUEST</th>\n",
       "      <th>IITAP3</th>\n",
       "      <th>IITAP3-GUEST</th>\n",
       "      <th>info</th>\n",
       "      <th>info2</th>\n",
       "      <th>KEMA10</th>\n",
       "      <th>kemA4</th>\n",
       "      <th>KRZ</th>\n",
       "      <th>library114</th>\n",
       "      <th>TP-LINK_B2765A</th>\n",
       "      <th>UPC Wi-Free</th>\n",
       "      <th>UPC8902044</th>\n",
       "      <th>wireless</th>\n",
       "      <th>00:16:53:4C:B1:F9</th>\n",
       "      <th>00:16:53:4C:B2:02</th>\n",
       "      <th>00:16:53:4C:B4:EB</th>\n",
       "      <th>00:16:53:4C:E9:1D</th>\n",
       "      <th>00:16:53:4C:F2:6A</th>\n",
       "      <th>00:16:53:4C:F5:2D</th>\n",
       "      <th>00:16:53:4C:F9:A4</th>\n",
       "      <th>00:16:53:4C:FA:60</th>\n",
       "      <th>00:16:53:4C:FA:67</th>\n",
       "      <th>48:5A:B6:54:35:DC</th>\n",
       "      <th>6B:C2:26:12:62:60</th>\n",
       "      <th>DANI 6B:C2:26:12:62:60</th>\n",
       "      <th>DM06082 48:5A:B6:54:35:DC</th>\n",
       "      <th>EV3 00:16:53:4C:E9:1D</th>\n",
       "      <th>EV3 00:16:53:4C:F2:6A</th>\n",
       "      <th>EV3 00:16:53:4C:FA:60</th>\n",
       "      <th>EV3 00:16:53:4C:FA:67</th>\n",
       "      <th>EV3BD 00:16:53:4C:F5:2D</th>\n",
       "      <th>IZE 00:16:53:4C:B1:F9</th>\n",
       "      <th>JOE 00:16:53:4C:F9:A4</th>\n",
       "      <th>MEGAROBOT 00:16:53:4C:B2:02</th>\n",
       "      <th>MrEv3 00:16:53:4C:B4:EB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>04550b4e-b5fc-4665-a043-18e82e94399a</td>\n",
       "      <td>2016-02-27 16:40:22.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>07a25de0-a013-486d-9463-404a348e05ee</td>\n",
       "      <td>1st Floor East Corridor</td>\n",
       "      <td>0.119910</td>\n",
       "      <td>-0.932650</td>\n",
       "      <td>0.049958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>-53.0</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>-55.0</td>\n",
       "      <td>-57.0</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93645336-eb2d-4983-950f-cb0e4191b986</td>\n",
       "      <td>2016-02-27 16:43:13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>07a25de0-a013-486d-9463-404a348e05ee</td>\n",
       "      <td>1st Floor East Corridor</td>\n",
       "      <td>1.275436</td>\n",
       "      <td>-1.024375</td>\n",
       "      <td>0.058756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>-68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>-73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7f210fdb-7018-454c-978b-9a595ee39130</td>\n",
       "      <td>2016-02-27 16:50:48.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>07a25de0-a013-486d-9463-404a348e05ee</td>\n",
       "      <td>1st Floor East Corridor</td>\n",
       "      <td>-0.506722</td>\n",
       "      <td>-0.964530</td>\n",
       "      <td>0.055499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-79.0</td>\n",
       "      <td>-74.0</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-85.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>-72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d9b0c804-5886-4b69-a65a-0ea9a423f5df</td>\n",
       "      <td>2016-02-27 16:53:22.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>07a25de0-a013-486d-9463-404a348e05ee</td>\n",
       "      <td>1st Floor East Corridor</td>\n",
       "      <td>0.557698</td>\n",
       "      <td>-0.950144</td>\n",
       "      <td>0.127510</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>-78.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>-64.0</td>\n",
       "      <td>-85.0</td>\n",
       "      <td>-85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d1bdb07f-23c9-4d73-a2c5-e24642778075</td>\n",
       "      <td>2016-02-27 16:51:31.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>07a25de0-a013-486d-9463-404a348e05ee</td>\n",
       "      <td>1st Floor East Corridor</td>\n",
       "      <td>-0.462596</td>\n",
       "      <td>-0.717116</td>\n",
       "      <td>0.083141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-84.0</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>-82.0</td>\n",
       "      <td>-86.0</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 measId          measTimestamp  Position X  Position Y  Position Z                                zoneId                 Zonename    meas X    meas Y    meas Z  gpsLatitude  gpsLongitude  gpsAltitude   N  109.0  AIT-L15  aut-sams-1  bolyai_E4_floor3  Bosch_Telemetry    dd  doa2  doa200  doa203  doa207  doa208  doa6  EET_3  FRM  GEIAKFSZ  IITAP1  IITAP1-GUEST  IITAP2  IITAP2-GUEST  IITAP3  IITAP3-GUEST  info  info2  KEMA10  kemA4   KRZ  library114  TP-LINK_B2765A  UPC Wi-Free  UPC8902044  wireless  00:16:53:4C:B1:F9  00:16:53:4C:B2:02  00:16:53:4C:B4:EB  00:16:53:4C:E9:1D  00:16:53:4C:F2:6A  00:16:53:4C:F5:2D  00:16:53:4C:F9:A4  00:16:53:4C:FA:60  00:16:53:4C:FA:67  48:5A:B6:54:35:DC  6B:C2:26:12:62:60  DANI 6B:C2:26:12:62:60  DM06082 48:5A:B6:54:35:DC  EV3 00:16:53:4C:E9:1D  EV3 00:16:53:4C:F2:6A  EV3 00:16:53:4C:FA:60  EV3 00:16:53:4C:FA:67  EV3BD 00:16:53:4C:F5:2D  IZE 00:16:53:4C:B1:F9  JOE 00:16:53:4C:F9:A4  MEGAROBOT 00:16:53:4C:B2:02  \\\n",
       "0  04550b4e-b5fc-4665-a043-18e82e94399a  2016-02-27 16:40:22.0         8.0         8.0         4.4  07a25de0-a013-486d-9463-404a348e05ee  1st Floor East Corridor  0.119910 -0.932650  0.049958          NaN           NaN          NaN NaN  -70.0      NaN       -80.0               NaN              NaN -83.0   NaN     NaN   -82.0   -74.0   -53.0 -83.0    NaN  NaN     -63.0   -55.0         -57.0   -78.0         -79.0   -74.0         -73.0   NaN    NaN     NaN    NaN -65.0         NaN             NaN          NaN         NaN       NaN                0.0                0.0                0.0                0.0                0.0                0.0                0.0                0.0                0.0                0.0                0.0                     1.0                        0.0                    0.0                    0.0                    0.0                    1.0                      1.0                    0.0                    1.0                          0.0   \n",
       "1  93645336-eb2d-4983-950f-cb0e4191b986  2016-02-27 16:43:13.0        12.0         9.0         4.4  07a25de0-a013-486d-9463-404a348e05ee  1st Floor East Corridor  1.275436 -1.024375  0.058756          NaN           NaN          NaN NaN  -69.0      NaN       -82.0               NaN              NaN -75.0   NaN     NaN     NaN   -82.0   -68.0   NaN    NaN  NaN     -65.0   -75.0         -81.0   -79.0         -80.0   -73.0         -73.0   NaN    NaN     NaN    NaN -72.0         NaN           -85.0          NaN         NaN       NaN                1.0                0.0                1.0                0.0                1.0                1.0                1.0                0.0                1.0                0.0                1.0                     0.0                        0.0                    0.0                    0.0                    0.0                    0.0                      0.0                    0.0                    0.0                          0.0   \n",
       "2  7f210fdb-7018-454c-978b-9a595ee39130  2016-02-27 16:50:48.0        23.0         8.0         4.4  07a25de0-a013-486d-9463-404a348e05ee  1st Floor East Corridor -0.506722 -0.964530  0.055499          NaN           NaN          NaN NaN  -65.0      NaN       -79.0               NaN              NaN -81.0   NaN   -85.0     NaN     NaN   -75.0   NaN    NaN  NaN     -79.0   -74.0         -82.0   -82.0         -81.0   -86.0         -86.0   NaN    NaN     NaN    NaN -85.0       -86.0           -72.0          NaN         NaN       NaN                0.0                0.0                0.0                0.0                0.0                0.0                0.0                0.0                0.0                0.0                0.0                     1.0                        0.0                    0.0                    1.0                    1.0                    1.0                      1.0                    1.0                    1.0                          0.0   \n",
       "3  d9b0c804-5886-4b69-a65a-0ea9a423f5df  2016-02-27 16:53:22.0        26.0         9.0         4.4  07a25de0-a013-486d-9463-404a348e05ee  1st Floor East Corridor  0.557698 -0.950144  0.127510          NaN           NaN          NaN NaN  -75.0      NaN       -66.0               NaN              NaN -83.0 -78.0   -75.0     NaN     NaN   -75.0   NaN    NaN  NaN     -84.0     NaN           NaN   -66.0         -64.0   -85.0         -85.0   NaN    NaN     NaN    NaN -89.0         NaN           -85.0          NaN         NaN       NaN                1.0                0.0                1.0                0.0                1.0                1.0                1.0                1.0                1.0                0.0                1.0                     0.0                        0.0                    0.0                    0.0                    0.0                    0.0                      0.0                    0.0                    0.0                          0.0   \n",
       "4  d1bdb07f-23c9-4d73-a2c5-e24642778075  2016-02-27 16:51:31.0        24.0         8.0         4.4  07a25de0-a013-486d-9463-404a348e05ee  1st Floor East Corridor -0.462596 -0.717116  0.083141          NaN           NaN          NaN NaN  -76.0      NaN       -83.0               NaN              NaN -86.0   NaN   -82.0     NaN     NaN   -82.0   NaN    NaN  NaN       NaN   -84.0         -81.0   -80.0         -82.0   -86.0         -87.0   NaN    NaN     NaN    NaN -81.0         NaN           -89.0          NaN         NaN       NaN                0.0                0.0                0.0                0.0                0.0                0.0                0.0                0.0                0.0                0.0                0.0                     1.0                        0.0                    0.0                    1.0                    1.0                    1.0                      1.0                    1.0                    1.0                          0.0   \n",
       "\n",
       "   MrEv3 00:16:53:4C:B4:EB  \n",
       "0                      0.0  \n",
       "1                      0.0  \n",
       "2                      1.0  \n",
       "3                      0.0  \n",
       "4                      1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"dataset.csv\", sep=\";\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following methods are used to create synthetic features. \n",
    "\n",
    "### The added features are the spherical coordinates of x, y and z, the products of the x and y coordinates as well as the products of x, y and z.\n",
    "\n",
    "### These features are added in hopes of better conveying the real relations between coordinates and measurements in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _calculate_spherical_coordinates(dataset) : \n",
    "    r=dataset[\"Position X\"]**2+dataset[\"Position Y\"]**2+dataset[\"Position Z\"]**2\n",
    "    r=np.sqrt(r)\n",
    "    tetha=dataset[\"Position Y\"]/r\n",
    "    tetha=np.arccos(tetha)\n",
    "    phi=dataset[\"Position Y\"]/dataset[\"Position X\"]\n",
    "    phi=np.tanh(phi)\n",
    "    return (r,tetha,phi)\n",
    "\n",
    "def create_synthetic_features(dataset):\n",
    "    x_y=dataset[\"Position X\"]*dataset[\"Position Y\"]\n",
    "    x_y_z=dataset[\"Position X\"]*dataset[\"Position Y\"]*dataset[\"Position Z\"]\n",
    "    (r,tetha,phi)=_calculate_spherical_coordinates(dataset)\n",
    "    synthetic= pd.DataFrame()\n",
    "    synthetic[\"x_y\"]=x_y\n",
    "    synthetic[\"x_y_z\"]=x_y_z\n",
    "    synthetic[\"r\"]=r\n",
    "    synthetic[\"tetha\"]=tetha\n",
    "    synthetic[\"phi\"]=phi\n",
    "    return(synthetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_AP_dataframe(selected_features, AP_name):\n",
    "    AP_df=selected_features.iloc[:,0:8]\n",
    "    AP_df[AP_name]=selected_features[AP_name]\n",
    "    AP_df= AP_df[pd.notnull(AP_df[AP_name])]\n",
    "    return AP_df\n",
    "    \n",
    "def get_AP_scaler(AP_df):\n",
    "    scaler=preprocessing.StandardScaler()\n",
    "    scaler.fit(AP_df)\n",
    "    return scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following methods are used to create the dataset from the original data. \n",
    "\n",
    "### The coordinates, and the synthetic features are added along with the WiFi RSSi measurements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features= dataset.iloc[:,14:45]\n",
    "selected_features.insert(0,'pos_x', dataset[\"Position X\"])\n",
    "selected_features.insert(1,'pos_y', dataset[\"Position Y\"])\n",
    "selected_features.insert(2,'pos_z', dataset[\"Position Z\"])\n",
    "selected_features[selected_features.pos_z != 0]\n",
    "synthetic_features=create_synthetic_features(dataset)\n",
    "selected_features.insert(3, \"x_y\", synthetic_features[\"x_y\"])\n",
    "selected_features.insert(4, \"x_y_z\", synthetic_features[\"x_y_z\"])\n",
    "selected_features.insert(5, \"r\", synthetic_features[\"r\"])\n",
    "selected_features.insert(6, \"tetha\", synthetic_features[\"tetha\"])\n",
    "selected_features.insert(7, \"phi\", synthetic_features[\"phi\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'>   </a>\n",
    "# Step Two: Dataset separation, scaling and simple filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After the DataFrame has been composed from the selected features, the problem of sparse data has to be solved.\n",
    " * Feed Forward Artificial Neural Networks does not handle sparse data well\n",
    "      - The data has to be converted into dense a form.\n",
    "      - NaN-s cannot be replaced with arbitrary values, as these would alter the outcome of the training and predictions.\n",
    " * Solution: \n",
    "      - Create dense DataFrames for each Access Point.\n",
    "      - df_list contains dataframes of coordinates which are the training data.\n",
    "      - target_list contains dataframes with associated target RSSI values.\n",
    "      - all dataframes are scaled individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list=list()\n",
    "scaler_list=list()\n",
    "target_list=list()\n",
    "df_list_unscaled=list()\n",
    "i=0\n",
    "for index, item in enumerate(selected_features.columns):\n",
    "    #Crude but works\n",
    "    if index>7:\n",
    "        df_list.append(get_AP_dataframe(selected_features, AP_name=item))\n",
    "        df_list_unscaled.append(get_AP_dataframe(selected_features, AP_name=item))\n",
    "        scaler_list.append(get_AP_scaler(df_list[i]))\n",
    "        df_list[i][:]=scaler_list[i].transform(df_list[i][:])\n",
    "        target_list.append(df_list[i].pop(df_list[i].columns[-1]))\n",
    "        i=i+1\n",
    "with open('before.txt', 'w') as f:\n",
    "    for dataframe in df_list:\n",
    "       print(dataframe.describe(), file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After the DataFrame lists have been created, WiFi Access Points which have less than hundred entries in the original data set are deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "11\n",
      "21\n",
      "25\n",
      "21\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "for _ in range(0, 2):\n",
    "    for index,dataframe in enumerate(df_list):\n",
    "        if(dataframe.size < 100):\n",
    "            print(index)\n",
    "            del df_list[index]\n",
    "            del target_list[index]\n",
    "            del scaler_list[index]\n",
    "            del df_list_unscaled[index]\n",
    "with open('after.txt', 'w') as f:\n",
    "    for dataframe in df_list:\n",
    "        print(dataframe.describe(), file=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'>   </a>\n",
    "# Step Three: Hyperparameter Training and Artificial Neural Network Model Building."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The created DataFrames can be used to create simple Feed Forward Networks in order to train the inferences between positions and WiFi RSSI signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Takes a long time to compute!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDataFrame= df_list[0].copy();\n",
    "target=testDataFrame.pop('109.0')\n",
    "x_train, x_test, y_train, y_test= train_test_split(testDataFrame, target)\n",
    "\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(50, 100, 200, 100, 50), (200, 400, 800, 400, 200), (1000, 2000, 1000)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['lbfgs','sgd', 'adam'],\n",
    "    'alpha': [0.03, 0.01, 0.003, 0.001, 0.0001],\n",
    "    'learning_rate_init': [0.03, 0.01, 0.003, 0.001, 0.0001],\n",
    "}\n",
    "\n",
    "clf= GridSearchCV(MLPRegressor(max_iter=1000, verbose=True, learning_rate=\"adaptive\"), parameter_space, n_jobs=-1, cv=3, verbose=True)\n",
    "print(\"Starting GridSearch Fit\")\n",
    "clf.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyperparameter training has been run with numerous parameters (not just the ones seen on the code block above.).\n",
    "\n",
    "Performance statistics have been collected in order to analyze the results.\n",
    "The resulting data can be seen in the gridstatistics.ipnb file.\n",
    "\n",
    "Decision trees, and apriori algorithm were used in order to determine important parameters, and parameter pairs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A list of Feed Forward models are trained with individual data sets.\n",
    "### Hyperparameter testing was done only on the first dataset. \n",
    "\n",
    "TODO :Models with high testing loss would have to be retrained with different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ANN_list():\n",
    "    ANN_List=[]\n",
    "    for (testDataFrame, target) in zip(df_list,target_list):\n",
    "        x_train, x_test, y_train, y_test= train_test_split(testDataFrame, target)\n",
    "        model= MLPRegressor(activation='relu', alpha=0.001, batch_size='auto', beta_1=0.9,\n",
    "               beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
    "               hidden_layer_sizes=(200, 300, 400, 300, 200), learning_rate='adaptive',\n",
    "               learning_rate_init=0.0001, max_iter=5000, momentum=0.5,\n",
    "               n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
    "               random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
    "               validation_fraction=0.1, verbose=False, warm_start=False)\n",
    "        model.fit(x_train, y_train)\n",
    "        ANN_List.append(model)\n",
    "        print(model.score(x_test, y_test))\n",
    "    return ANN_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list=create_ANN_list()\n",
    "with open(\"model_list.txt\", \"wb\") as fp:\n",
    "    pickle.dump(model_list, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'>   </a>\n",
    "# Step Four: Genetic Algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following block contains a class for neural network inversion with a genetic algorithm. \n",
    "### The genetic algorithm structure was constructed using the DEAP framework.\n",
    "\n",
    "* The creator function creates individuals based on the generate_individual() function.\n",
    "\n",
    "* The evaluation function calculates the error between individuals in the generation and the target values.\n",
    "\n",
    "* generate_valid_pop() evaluates individuals, and creates a new generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GA_Inverter():\n",
    "    \n",
    "    def __init__(self, index, toolbox, ind_size, pop_size, elite_count):\n",
    "        self.creator=creator\n",
    "        self.index=index\n",
    "        self.toolbox=toolbox\n",
    "        self.IND_SIZE=ind_size\n",
    "        self.POP_SIZE=pop_size\n",
    "        self.elite_count=elite_count\n",
    "        \n",
    "    def creator_function(self):\n",
    "        return self.creator.Individual(self.generate_individual())\n",
    "\n",
    "\n",
    "    def generate_individual(self):\n",
    "        x= random.randint(math.floor(df_list_unscaled[self.index].min()[0]),math.floor(df_list_unscaled[self.index].max()[0]))\n",
    "        y = random.randint(math.floor(df_list_unscaled[self.index].min()[1]),math.floor(df_list_unscaled[self.index].max()[1]))\n",
    "        z = random.randint(math.floor(df_list_unscaled[self.index].min()[2]),math.floor(df_list_unscaled[self.index].max()[2]))\n",
    "        x_y=x*y\n",
    "        x_y_z=x*y*z\n",
    "        r=x**2+y**2+z**2\n",
    "        r=np.sqrt(r)\n",
    "        if r is not 0:\n",
    "            tetha=y/r\n",
    "        else:\n",
    "             tetha=0\n",
    "        tetha=np.arccos(tetha)\n",
    "        if(x is not 0):\n",
    "            phi=y/x\n",
    "        else:\n",
    "            phi=0\n",
    "        phi=np.tanh(phi)\n",
    "        return scaler_list[self.index].transform([[x, y, z, x_y, x_y_z, r, tetha, phi,0]]).tolist()[0][:-1]\n",
    "\n",
    "\n",
    "    def evaluate(self,individual, regressor, y_pred):\n",
    "        d=(((regressor.predict(np.asarray(individual).reshape(1, -1))-y_pred)**2).sum(),)\n",
    "        return d\n",
    "\n",
    "    def initialize_invertion_functions(self):\n",
    "        self.creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "        self.creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "        #toolbox.register(\"attr_float\", random.random())\n",
    "        self.toolbox.register(\"population\", tools.initRepeat, list,  self.creator_function, n=self.POP_SIZE )\n",
    "        self.pop = self.toolbox.population()\n",
    "        self.toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "        self.toolbox.register(\"mutate\", tools.mutShuffleIndexes)\n",
    "        self.toolbox.register(\"selectWorst\", tools.selWorst)\n",
    "        self.toolbox.register(\"selectBest\", tools.selBest)\n",
    "        self.toolbox.register(\"evaluate\", self.evaluate)\n",
    "\n",
    "\n",
    "        \n",
    "    def generate_valid_pop(self, index, y_predict, model, scaler, CXPB, MUTPB, NGEN, DESIRED_OUTPUT, OUTPUT_TOLERANCE, ELIT_CNT = 10):\n",
    "    \n",
    "        fitnesses=list()\n",
    "        # evaluation\n",
    "        for individual in self.pop:\n",
    "            #TODO USE SCALER LIST [INDEX], IT DOESNT WORK FOR SOME REASON\n",
    "            temp=self.toolbox.evaluate(individual, model, scaler.transform([[0,0,0,0,0,0,0,0,DESIRED_OUTPUT]] )[0][8] )\n",
    "            fitnesses.append(temp)\n",
    "        for ind, fit in zip(self.pop, fitnesses):\n",
    "              ind.fitness.values = fit\n",
    "\n",
    "        for g in range(NGEN):\n",
    "\n",
    "            elits = self.toolbox.selectBest(self.pop,k= ELIT_CNT)\n",
    "            elits = list(map(self.toolbox.clone, elits))\n",
    "            offsprings = self.toolbox.selectWorst(self.pop,k= self.POP_SIZE - ELIT_CNT)\n",
    "\n",
    "            offsprings = list(map(self.toolbox.clone, offsprings))\n",
    "\n",
    "            sumFitness = 0\n",
    "            for ind in self.pop:\n",
    "                sumFitness = sumFitness+ ind.fitness.values[0]\n",
    "\n",
    "            for offspring in offsprings:\n",
    "                    parents = tools.selRoulette(self.pop,2)\n",
    "                    parents = list(map(self.toolbox.clone, parents))\n",
    "                    offspring = tools.cxTwoPoint(parents[0],parents[1])[0]\n",
    "                    del offspring.fitness.values\n",
    "\n",
    "                # Evaluate the individuals with an invalid fitness\n",
    "            invalid_ind = [ind for ind in offsprings if not ind.fitness.valid]\n",
    "            fitnesses=list()\n",
    "            for index, individual in enumerate(invalid_ind):\n",
    "                fitnesses.append( self.toolbox.evaluate(individual, model, y_predict[index]))\n",
    "            for ind, fit in zip(invalid_ind, fitnesses):\n",
    "                  ind.fitness.values = fit\n",
    "\n",
    "            for i in range(ELIT_CNT):\n",
    "                self.pop[i] = elits[i]\n",
    "            for i in range(self.POP_SIZE - ELIT_CNT):\n",
    "                self.pop[i+ELIT_CNT] = offsprings[i]\n",
    "\n",
    "            for index, individual in enumerate(self.pop):\n",
    "                temp=self.toolbox.evaluate(individual, model, y_predict[index])\n",
    "            fitnesses.append(temp)\n",
    "            for ind, fit in zip(self.pop, fitnesses):\n",
    "                  ind.fitness.values = fit\n",
    "\n",
    "        return [ind for ind in self.pop if ind.fitness.values[0] <2]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following function returns dictionaries of AP names and RSSI values, based on measurement time. \n",
    "\n",
    "Every dictionary corresponds to a measurement time, denoted by the index in the original data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs_by_time(selected_features, df_list_unscaled)\n",
    "    list_of_inputs=[]\n",
    "        for index in selected_features.index:\n",
    "            inputs_list_by_time={}\n",
    "            for df in df_list_unscaled:\n",
    "                df_mod=pd.DataFrame(df.iloc[:, -1])\n",
    "                for i in range(df_mod.count()[0]):\n",
    "                    if df_mod.index[i] == index:\n",
    "                        inputs_list_by_time.update({df_mod.columns[0]:df_mod.iloc[0,0]})\n",
    "            list_of_inputs.append(inputs_list_by_time)\n",
    "    return list_of_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to invert the trained neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def invert_all(df_list, target_list, model_list, scaler_list,CXPB, MUTPB, NGEN, DESIRED_OUTPUT, OUTPUT_TOLERANCE):\n",
    "        inverted_list=[]\n",
    "        for index,(testDataFrame, target) in enumerate(zip(df_list,target_list)):\n",
    "            print(index)\n",
    "            x_train, x_test, y_train, y_test= train_test_split(testDataFrame, target)\n",
    "            inverter=GA_Inverter(0, base.Toolbox(), x_test.iloc[0].size, len(x_test.index), 10)\n",
    "            inverter.initialize_invertion_functions()\n",
    "            y_pred=model_list[index].predict(x_test)\n",
    "            valid_pop=inverter.generate_valid_pop(index, y_pred, model_list[index], scaler_list[index], CXPB, MUTPB, NGEN, DESIRED_OUTPUT, OUTPUT_TOLERANCE)\n",
    "            dataset_inverted=df_list[index].copy();\n",
    "            dataset_original=df_list_unscaled[index].copy().values.tolist();\n",
    "            dataset_original_df=df_list_unscaled[index].copy()\n",
    "            dataset_inverted.drop(dataset_inverted.index, inplace=True)\n",
    "            for ind, row in enumerate(valid_pop):\n",
    "                dataset_inverted.loc[ind] = valid_pop[ind]\n",
    "            dataset_inverted['target']= pd.Series(target_list[index])\n",
    "            dataset_inverted=scaler_list[index].inverse_transform(dataset_inverted)\n",
    "            inverted_list.append(dataset_inverted)\n",
    "        return inverted_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to predict coordinates based on the inverted values.\n",
    "\n",
    "The prediction takes a weighted sum of the predicted positions of every dictionary in the list to predict a position.\n",
    "Every invertion coordinate prediction creates a 3D manifold surface of possible positions in the 3D space. \n",
    "The intersection of these predicted coordinates give the most accurate predicted coordinates.\n",
    "\n",
    "\n",
    "  $\\bigcap \\mathbb{I} (\\pi, \\epsilon)$, where  $\\mathbb{I}$  is the invertion function  $ \\mathbb{I}: R^n \\rightarrow \\mathbb{N}^3$, and $\\pi$ is the WiFi RSSI Signal Strenght.\n",
    "  $\\mathbb{I}$\n",
    "\n",
    "There are other methods which could be used to calculate the intersection of these coordinates, but currently only this method is implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_coordinates(inverted_positions):\n",
    "    gen_x_coord=[]\n",
    "    gen_y_coord=[]\n",
    "    for  values in  inverted_positions.values():\n",
    "        for g_val in values:\n",
    "            gen_x_coord.append(g_val[0])\n",
    "            gen_y_coord.append(g_val[1])\n",
    "    gen_x_coord=pd.Series(gen_x_coord)\n",
    "    gen_y_coord=pd.Series(gen_y_coord)\n",
    "    return(np.average(gen_x_coord[gen_x_coord < np.max(selected_features[\"pos_x\"])]),np.average(gen_y_coord[gen_y_coord < np.max(selected_features[\"pos_y\"])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error calculation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error(predicted_cooridnates, actual_coordinates):\n",
    "    return np.array(((predicted_cooridnates - actual_coordinates) ** 2)).mean(axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Driver code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_inputs=get_inputs_by_time(selected_features, df_list_unscaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CXPB, MUTPB, NGEN = 0.5, 0.1, 1000\n",
    "DESIRED_OUTPUT= -80\n",
    "OUTPUT_TOLERANCE= 2\n",
    "output_list=get_output_list(list_of_inputs,CXPB, MUTPB, NGEN, OUTPUT_TOLERANCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list=[]\n",
    "for invereted_positions in inverted_positions_list:\n",
    "    predicted_cooridnates=np.array(predict_coordinates(inverted_positions))\n",
    "    calculate_error(predicted_cooridnates, actual_coordinates)\n",
    "    error_list.append(calculate_error(predicted_cooridnates, actual_coordinates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Function for the visualization of the invertion function results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_inverted(dataset_unscaled, dataset_inverted):\n",
    "    dataset_original=dataset_unscaled.copy().values.tolist();\n",
    "    dataset_original_df=dataset_unscaled.copy()\n",
    "    fig, (ax1, ax2, ax3) =plt.subplots(ncols=3, nrows=1, figsize= ( 20, 6))\n",
    "    x_number_list_o = [values[0] for values in dataset_original ]\n",
    "    # y axis value list.\n",
    "    y_number_list_o = [values[1] for values in dataset_original ]\n",
    "        # Draw point based on above x, y axis values.\n",
    "    ax1.scatter(x_number_list_o, y_number_list_o)\n",
    "    ax1.set_xlim([0-5, dataset[\"Position X\"].max()+5])\n",
    "    ax1.set_ylim([0-5, dataset[\"Position Y\"].max()+5])\n",
    "    # Set chart title.\n",
    "    ax1.title.set_text(\"Original coordinates of the dataset\") \n",
    "    # Set x, y label text.\n",
    "    ax1.set_xlabel(\"X\")\n",
    "    ax1.set_ylabel(\"Y\")\n",
    "    x_number_list = [values[0] for values in dataset_original if values[8] > DESIRED_OUTPUT - OUTPUT_TOLERANCE and values[8] < DESIRED_OUTPUT +OUTPUT_TOLERANCE]\n",
    "    # y axis value list.\n",
    "    y_number_list = [values[1] for values in dataset_original if values[8] > DESIRED_OUTPUT - OUTPUT_TOLERANCE and values[8] < DESIRED_OUTPUT +OUTPUT_TOLERANCE]\n",
    "        # Draw point based on above x, y axis values.\n",
    "    ax2.scatter(x_number_list, y_number_list)\n",
    "    ax2.set_xlim([0-5, dataset[\"Position X\"].max()+5])\n",
    "    ax2.set_ylim([0-5, dataset[\"Position Y\"].max()+5])\n",
    "    # Set chart title.\n",
    "    ax2.title.set_text(\"Original coordinates reduced by currently detected WiFi RSSI\") \n",
    "    # Set x, y label text.\n",
    "    ax2.set_xlabel(\"X\")\n",
    "    ax2.set_ylabel(\"Y\")\n",
    "    x_number_list = [values[0] for values in dataset_inverted ]\n",
    "    # y axis value list.\n",
    "    y_number_list = [values[1] for values in dataset_inverted ]\n",
    "    ax3.scatter(x_number_list, y_number_list, color=\"r\" )\n",
    "    ax3.set_xlim([0-5, dataset[\"Position X\"].max()+5])\n",
    "    ax3.set_ylim([0-5, dataset[\"Position Y\"].max()+5])\n",
    "    # Set chart title.\n",
    "    ax3.title.set_text(\"Inverted coordinates by genetic algorithm\")\n",
    "    # Set x, y label text.\n",
    "    ax3.set_xlabel(\"X\")\n",
    "    ax3.set_ylabel(\"Y\")\n",
    "    plt.savefig('coordinatesinverted.pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"650\"\n",
       "            src=\"1cinvert1.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2819e328208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import IFrame    \n",
    "display(IFrame(\"1cinvert1.pdf\", width=900, height=650))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "MagickWand shared library not found.\nYou probably had not installed ImageMagick library.\nTry to install:\n  http://docs.wand-py.org/en/latest/guide/install.html#install-imagemagick-on-windows",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\wand\\api.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m     \u001b[0mlibraries\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_library\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\wand\\api.py\u001b[0m in \u001b[0;36mload_library\u001b[1;34m()\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlibwand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibmagick\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cannot find library; tried paths: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mrepr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtried_paths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: cannot find library; tried paths: []",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-3cfc4b005d20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mwand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mWImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'1cinvert2.pdf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\wand\\image.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0massertions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlibc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibmagick\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibrary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcolor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mColor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\wand\\assertions.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;31m# Lazy load recursive import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcolor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mColor\u001b[0m  \u001b[1;31m# noqa: E402\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\wand\\color.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlibrary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcdefs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstructures\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMagickPixelPacket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPixelInfo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\wand\\api.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    175\u001b[0m     raise ImportError('MagickWand shared library not found.\\n'\n\u001b[0;32m    176\u001b[0m                       \u001b[1;34m'You probably had not installed ImageMagick library.\\n'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m                       'Try to install:\\n  ' + msg)\n\u001b[0m\u001b[0;32m    178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;31m#: (:class:`ctypes.CDLL`) The MagickWand library.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: MagickWand shared library not found.\nYou probably had not installed ImageMagick library.\nTry to install:\n  http://docs.wand-py.org/en/latest/guide/install.html#install-imagemagick-on-windows"
     ]
    }
   ],
   "source": [
    "display(IFrame(\"1cinvert2.pdf\", width=900, height=650))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"600\"\n",
       "            height=\"300\"\n",
       "            src=\"1cinvert2.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x2819e144e08>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(IFrame(\"1cinvert3.pdf\", width=900, height=650))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(IFrame(\"2cinvert1.pdf\", width=900, height=650))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(IFrame(\"2cinvert2.pdf\", width=900, height=650))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(IFrame(\"2cinvert3.pdf\", width=900, height=650))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
